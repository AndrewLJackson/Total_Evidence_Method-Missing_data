\documentclass[11pt]{letter}
\usepackage[a4paper,left=2.5cm, right=2.5cm, top=1cm, bottom=1cm]{geometry}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[colorlinks = true, urlcolor = blue]{hyperref} %hyperlinks
\usepackage[osf]{mathpazo}
\signature{Thomas Guillerme \\ Natalie Cooper}
\address{Zoology building \\ Trinity College Dublin \\ Dublin 2, Ireland \\ \\ guillert@tcd.ie}
\longindentation=0pt
\begin{document}

\begin{letter}{}

RE: PLOS ONE Decision: PONE-D-15-05911 - [EMID:ffa50492e76c2059]

Dear Dr Fontaneto

Please find enclosed our resubmission of our manuscript @@@[title]. We include below details of how we have dealt with the reviewer's comments.

We would however, like to draw your attention to a couple of points. Firstly, while we understand the difficulties of obtaining reviewers for papers, we were very disappointed to have the previous decision made based on just one review. As pointed out in your email, this reviewer responded immediately. We suspect they rushed their assessment because they make several comments about our paper that are completely incorrect, and would have been noticed in a thorough reading of the manuscript. For example, the reviewer says that our data are not available when we clearly state on @@@[page and lines] that all the data are deposited in figshare @@@[link]. We suspect that had a second reviewer been found the decision might have been different. %maybe recheck that

Secondly, the reviewer clearly misunderstood the meaning of the term ``statistics". Statistics does not mean that p-values need to be used. In this case we could have applied t-tests, and given the reviewer the p-values they request, but this would only tell us that the means of the distributions are significantly different, not that the distributions differ. We chose instead to use the Bhattacharya coefficient, which admittedly is an unfamiliar statistic to many but we feel we made a lot of effort to explain how this metric works in the text (and this method was suggested to us by a professional statistician!). The reviewer however appears to have refused to engage with this and instead has fixated on the lack of p-values.



\textcolor{ForestGreen}{From: PLOS ONE <em@editorialmanager.com<mailto:em@editorialmanager.com> \\
To: Thomas Guillerme <guillert@tcd.ie<mailto:guillert@tcd.ie> \\
Reply-To: PLOS ONE <plosone@plos.org<mailto:plosone@plos.org> \\
Date: 20 April 2015 12:25:39 IST \\ \\
Subject: PLOS ONE Decision: PONE-D-15-05911 - [EMID:ffa50492e76c2059] \\
PONE-D-15-05911 \\
Effects of missing data on topological inference using a Total Evidence approach \\
PLOS ONE \\ \\
Dear Mr Guillerme, \\
Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we have decided that your manuscript does not meet our criteria for publication and must therefore be rejected. \\
First of all, apologies for the long delays. We immediately received the comments from the first reviewer and in the meanwhile another reviewer agreed to send us comments but failed to do so, even after several reminders. Thus, I now have to reach a decision with only one reviewer.
Unfortunately, the comments from the only reviewer we have are rather negative and the problems that have been highlighted too many. Please, go through all the comments of the reviewer: I think that they all make sense and should be addressed and solved to produce a more convincing and less ambiguous story. \\
If you think that the issues can be solved by new analyses, we will be happy to reconsider a new version of the manuscript as a re-submission. \\
I am sorry that we cannot be more positive on this occasion, but hope that you appreciate the reasons for this decision. \\
Yours sincerely, \\ \\
Diego Fontaneto \\ 
Academic Editor \\
PLOS ONE}

\textcolor{blue}{Reviewers' comments:}

\textcolor{blue}{Reviewer's Responses to Questions}

\textcolor{blue}{Comments to the Author}

\textcolor{blue}{-------------------------}

\textcolor{blue}{1. Is the manuscript technically sound, and do the data support the conclusions?}

\textcolor{blue}{The manuscript must describe a technically sound piece of scientific research with data that supports the conclusions. Experiments must have been conducted rigorously, with appropriate controls, replication, and sample sizes. The conclusions must be drawn appropriately based on the data presented.}

\textcolor{blue}{Reviewer $\#$ 1: No}

See our detailed response below.

\textcolor{blue}{-------------------------}

\textcolor{blue}{2. Has the statistical analysis been performed appropriately and rigorously?}

\textcolor{blue}{Reviewer $\#$ 1: No}

See our detailed response below.

\textcolor{blue}{-------------------------}

\textcolor{blue}{3. Does the manuscript adhere to the PLOS Data Policy?}

\textcolor{blue}{Authors must follow the PLOS Data policy, which requires authors to make all data underlying the findings described in their manuscript fully available without restriction. Please refer to the author’s Data Availability Statement in the manuscript. All data and related metadata must be deposited in an appropriate public repository, unless already provided as part of the submitted article or supporting information. If there are restrictions on the ability of authors to publicly share data—e.g. privacy or use of data from a third party— these reasons must be specified.}

\textcolor{blue}{Reviewer $\#$ 1: No}

All the data generated by the simulation is directly available on \href{http://figshare.com/articles/Effect_of_missing_data_on_topological_inference_using_a_total_evidence_approach/1306861}{FigShare}. Note that along with the data we share the full code used for repeating the submitted manuscript, from simulating the data to generating the figures and compiling the manuscript (available on \href{https://github.com/TGuillerme/Total_Evidence_Method-Missing_data}{GitHub}. All this code is provided with a detailed description of each step that we are happy to develop if needed. However, we do apologise since we forgot to add this as a separated section in the supporting information section. We added the following part to the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
\textbf{Data reproducibility and availability.} All the code used in this analysis is available on \href{https://github.com/TGuillerme/Total_Evidence_Method-Missing_data}{\color{blue}{GitHub}} with some information on how to use the various functions. Additionally all the simulated data is available on \href{http://figshare.com/articles/Effect_of_missing_data_on_topological_inference_using_a_total_evidence_approach/1306861}{\color{blue}{FigShare}}.
\end{minipage}

\textcolor{blue}{-------------------------}

\textcolor{blue}{4. Is the manuscript presented in an intelligible fashion and written in standard English?}

\textcolor{blue}{PLOS ONE does not copyedit accepted manuscripts, so the language in submitted articles must be clear, correct, and unambiguous. Any typographical or grammatical errors should be corrected at revision, so please note any specific errors here.}

\textcolor{blue}{Reviewer $\#$ 1: Yes}

\textcolor{blue}{-------------------------}

\textcolor{blue}{5. Review Comments to the Author}


\textcolor{blue}{Please use the space provided to explain your answers to the questions above. You may also include additional comments for the author, including concerns about dual publication, research ethics, or publication ethics. (Please upload your review as an attachment if it exceeds 20,000 characters)}

\textcolor{blue}{Reviewer $\#$ 1: This paper tackles an interesting questions. Despite some problems noted below, the experimental design seems adequate.}

\textcolor{blue}{Unfortunately the data analysis performed is simply the calculation of a number of summary statistics about the overlap between the estimates returned for different simulation conditions. I suspect that if they authors take some time to do statistics (calculate some P-values, confidence intervals, or take a Bayesian perspective), they'll be able to make a statistical case for most of the points that they are trying to make. But I just don't think that a simulation comparison should be publishable without *some* statistical analysis (beyond the calculation of summaries).}

We are slightly concerned by the reviewer's misconception of the term ``statistics" and suspicions (``I suspect that if they authors take some time to do statistics (calculate some P-values, confidence intervals, or take a Bayesian perspective") since: (1) t-tests and p-values are useful in some cases but have several limitations especially when one compares distributions that are not normal (in this study, we compared the modal value of topological differences, making any test comparing the mean value useless) and can be biased towards small values (i.e. significant ones) when the sample sizes are big; (2) concerning the confidence intervals, we actually did systematically calculate them; ans (3) we are not convinced by a Bayesian approach for comparing distributions.

\textcolor{blue}{The bias in the analysis in favor of Bayesian methods makes the recommendation to use Bayesian methods less satisfying.}

Our results did indeed biased us in favour of using a Bayesian approach to fix topology since our results clearly indicate that it is less likely to generate a wrong topology using a Bayesian approach (see Figure 4 and 5 and discussion line 472 to 496 in the first submission manuscript).

\textcolor{blue}{The use of Mk rather than Mkv makes the study less relevant to real data analyses.}

The Mk model assumes that some morphological characters \textbf{can} be constant and the Mkv model assumes that \textbf{all} the characters are variable. Although the reviewer is right that real data analyses do not contain invariable (constant) morphological characters, we designed our simulations to be a generalisation of real data. Because we sampled the morphological characters rate from a gamma distribution with $\alpha$=0.5, some morphological characters had only a few state changes accross the matrix. When removing the data, there was a probability for these characters to be constant (e.g. if all the taxa in the matrix appart from one had a character state 0 for a given character and only one taxa had a state 1 for the same character, if that taxa had no data available for that character, then the character appeared to be constant in the matrix). Note that both RAxML and MrBayes do not distinguish between both models since the Mkv model is just a particular case of the Mk model and are not distinguished either in the original publication that we cite in the manuscript (Lewis 2001). We've changed the mentions of the Mk model to Mkv model throughout the new manuscript.

%Add note that we changed it along the text. RAxML and MrBayes are using default.

\textcolor{blue}{Many of the equations are incorrect.}

See our detailed response below.

\textcolor{blue}{If there was a mention of the data being deposited, I missed it. I apologize if I did miss it.}

See our comment above on data availability and reproducibility.

\textcolor{blue}{-------------------------}

\textcolor{blue}{Some specific concerns:}


\textcolor{blue}{line 25 and elsewhere: incorrect smart quotes in ``best", ``classical"...}

We fixed the smart quotes in the new manuscript.

\textcolor{blue}{line 88 ``used it to infer a matrix" $->$ ``used it to simulate a matrix". ``inference" is used in place of simulation elsewhere.}

We changed ``infer" into ``simulate" both at line 88 and in the Figure 1 caption.

\textcolor{blue}{line 112: does diversitree just stop simulating when it reaches the correct number of tips, or does it deal with the biases that can result from doing that? (Stadler 2011 is the ref for a discussion of this issues, I believe)}

%TO CHECK!
Lines 116 to 118 in the previously submitted manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
To avoid biasing our simulations towards either living or fossil taxa and to make each simulation comparable, we implemented a rejection sampling algorithm to select only trees with 25 living and 25 fossil taxa.
\end{minipage}

Lines @@@ in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
To avoid biasing our simulations towards either living or fossil taxa and to make each simulation comparable, we implemented a rejection sampling algorithm to select only trees with 25 living and 25 fossil taxa. In practice, we generated $x$ birth-death trees using the \texttt{tree.bd} function from the \texttt{diversitree R} package (FitzJohn) until we obtained $y$ trees with the right number of living and fossil taxa.
\end{minipage}

\textcolor{blue}{line 113: `` rates from a uniform distribution " with what upper and lower bounds?}

Both birth ($\lambda$) and death ($\mu$) parameters are respectively speciation and extinction probability (bounded between 0 and 1). We added this precision in the new version of the manuscript:

Lines 112 to 114 in the previously submitted manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
We generated the tree using a birth death process by sampling speciation ($\lambda$) and extinction ($\mu$) rates from a uniform distribution but maintaining $\lambda$ $>$ $\mu$.
\end{minipage}

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
We generated the tree using a birth death process by sampling speciation ($\lambda$) and extinction ($\mu$) rates from a uniform probability distribution (between 0 and 1) but maintaining $\lambda$ $>$ $\mu$.
\end{minipage}

\textcolor{blue}{line 118: wih 25 living and 25 fossil taxa. Are the fossils just put at the extinction point for the extinct lineages?}

Yes. We clarified as follow:

Lines 118-119 in the previously submitted manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
[We] select only trees with 25 living and 25 fossil taxa.
\end{minipage}

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
[We] select only trees with 25 living and 25 fossil taxa. The fossil taxa where considered as unique points at the end of extinct lineages.
\end{minipage}

\textcolor{blue}{line 110 - line 120. The procedure for generating a tree with fossils is a valid procedure. But it is idiosyncratic, which will make these results harder to relate to other work. Easy of comparability with other work is one of the advantages of using formally characterized models. In this case, I think that using the TreeSim package http://cran.r-project.org/web/packages/TreeSim/TreeSim.pdf would have led to a study with higher impact. This part of the methods section would be reduced to stating the parameter values chosen, and other workers could study similar tree generation simulations. As it stands, it is unlikely that other workers will every generate trees in precisely the way that the authors do. Thus, there will always be a ``however, Guillerme and Cooper generated their trees under a different model..." caveat necessary when discussing this work in the context of other work.}

We do not agree with this reviewer's comment. Even if our study might be idiosyncratic, we beleive it is not due to the use of the \texttt{diversitree} package instead of the \texttt{TreeSim} package. Both perform in generating birth-death trees correctly and are well curated and maintained. However, we chose to use the \texttt{diversitree} package rather than the \texttt{TreeSim} package exactly for making the results of our study more applicable to other ones. In fact, the publication associated with the diversitree package (FitzJohn 2012, Methods in Ecology and Evolution) has been cited three times more (155 cites on Google Scholar) than the publication associated with the \texttt{TreeSim} package (Stadler 2011, Systematic Biology - 55 cites on Google Scholar).

\textcolor{blue}{line 126 ``random base frequencies" is too vague. Dirichlet(1, 1, 1, 1) perhaps?}

We clarified as follow:

Lines 125 to 126 in the previously submitted manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
The matrix [...] was generated [...] using the HKY model with random base frequencies[...]
\end{minipage}

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
The matrix [...] was generated [...] using the HKY model with random base frequencies (sampled from a uniform probability distribution bounded between 0 and 1 with the total frequency for the four bases equal to 1)[...]
\end{minipage}

\textcolor{blue}{Do the simulations apply ascertainment biases as described by Lewis' Mkv (2001) model? It seems like they should... At minimum, the point should be discussed.}

We are not entirely sure if the reviewers refers to a sampling bias or to the problem link to constant characters described in Lewis (2001) (acquisition bias). If the reviewers are referring to the second (acquisition bias), both phylogenetic inference software we used (RAxML and MrBayes) are correcting for the this bias (-K MK  see Supplementary information 1 for the full list of commands). Also, the effect of the acquisition bias is to inflate branch length which is an aspect of the phylogeny we didn't explored in this study (focusing on topology). See response below to the comment \color{blue}{\textit{The use of Mk rather than Mkv makes the study less relevant to real data analyses.}}.

\textcolor{blue}{line 171 - 177: the authors need to explain the order of operations for the $M_F$ vs $M_C$ masking. It makes a difference. If you mask out $M_F$ percentage of cells, and then mask $M_C$ percentage of columns, it is possible (indeed very probable) that the percentage of missing data in fossil characters that remain will not be $M_F$ after some of the morphological columns are removed. If you mask by $M_C$ first, and then $M_F$, the resulting matrices will always have $M_F$ percentage missing data (modulo rounding error) in the simulated realizations.}

We clarified this point ($M_C$ comes second). %change in manuscript
Also, we clarified the potential confusion between the amount of data removed in one parameter ($M_F$ = 10\% for example) and the amount of missing data in the morphological matrix (5\%). %change in manuscript

\textcolor{blue}{Header for 3. should be ``building phylogenetic estimates" or ``estimating phylogenies" because the previous section described how the phylogenies and character data were ``built."}

We changed the Header 3 to infering phylogenies. %change in manuscript

\textcolor{blue}{RAxML searching: it would be nice to see some searches started from the true tree. This is clearly not an option for real data sets, but it is helpful in simulation studies because it lets the reader determine if the results could be an artifact of insufficient tree searching.}

%Probably no impact since it's not using an MCMC. But should we try it? (approx. one to two (max) month calculation).

\textcolor{blue}{Filtering the data sets for strong bootstrap support under the full data analysis surely introduces some bias in favor of the no-missing data analyses.}

We implemented this step of keeping trees with a minimum total median bootstrap to make the topological comparisons more robust. If the no-missing data tree has low node support, it is likely that the changes in topology for the missing data trees are not linked to our focal question (the effect of removing characters, living taxa or fossils) but just to the fact that low supported nodes can be just random.

\textcolor{blue}{MrBayes: using strongly informative priors for the true parameters does more than speed up the searching, it represents an ``unfair" advantage (an option that would not be availble in real data analysis in which one does not know the true values) for the Bayesian method. This makes the studies report of superior behavior of Bayesian methods less persuasive.}

We would like to emphasize that we are looking at topology and morphological data, our priors are on nucleotid frequencies and on TT ratio. This remains unchanged in all our trees. Also, we would like to emphasize on the ``speed up" part that was mandatory since the analysis took 1.5 CPU century including our ``unfair" methodological choices. We had to choose between extracting a global pattern (more faster chains) rather than some specific analysis (fewer slower chains).

\textcolor{blue}{line 254: RF measures the difference between the number of clades and the twice number of shared clades across two trees. The statement that it ``measures the number of shared clades across two trees" should be revised.}

%check

\textcolor{blue}{line 258: RF is 0 (not 1) when the trees are identical. It's maximum (for 2 rooted binary trees) is 2(n-2) not n-2.}

%check

\textcolor{blue}{The ``scaling" to produce the Normalized RF ``distance" is confusing. It is also inverting the sign of the distance, so it has become a measure of similarity.}

%check

\textcolor{blue}{line 275: why isn't the upper bound of the triples distance n choose 3 (instead of n choose 4). I think you got the formula from an unrooted quartet distance.}

%check

\textcolor{blue}{Using the BC stat may be similar in spirit to using a t-test, but it is not equivalent.}

We clarified as follow:

Lines 308 to 309 in the previously submitted manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
Note that this is equivalent to performing a two-sided t-test.
\end{minipage}

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
Note that this is similar to performing a two-sided t-test for comparing two distribution.
\end{minipage}


\textcolor{blue}{Figure 3: B is confusing. If both curves are probability distributions, then they both have to integrate to 1. So B(y) can't cover just a subset of the area covered by B(x).}

%Fix probability distributions -> "just" distributions


\textcolor{blue}{``Combined effect of missing data parameters" section ANOVA or multiple regression are the appropriate analyses to tease apart multiple interacting factors. Here the authors opt to describe results without statistical tests, which is disappointing.}

This comment links back to the reviewer's misconception of the term ``statistics" and suspicions. ANOVA or multiple regression analysis might the appropriate analyses in some cases but we believe it isn't here. %Not comparing means, non normal distributions. ANd non-parametric version (e.g. Kruskal Wallis) not approriate either.

\textcolor{blue}{line 398: ``mMthods" -> ``Methods"}

We fixed this typo.

\textcolor{blue}{line 420: contra the statement here, a consensus collapsing to a polytomy will affect the RF distance (could go up or down, but it will change).}

%Change to "affect less" or something like that.

\textcolor{blue}{-------------------------}

\textcolor{blue}{Supplement 2:}
\textcolor{blue}{more confusion about the min RF here. Also note that if you are counting the entire leaf set as a clade (e.g the star tree having N=1), then the number of clades in rooted binary tree is n-1 (not n-2). Equation 3 has an extra ``-2" As stated it implies that the max RF distance for n=3 is 0, when the correct answer is 2.}

%check

\textcolor{blue}{The definition of the scaled RF implies that it is never positive (sinc the numerator cannot be positive and the denominator is positive).}

%check

\textcolor{blue}{The decision to use Yule trees as the base line for the mean distance is not explained, and seems odd given that the true tree are not Yule trees. I'm not sure that it makes much difference, but it is odd.}

%Because we follow Bogdanowicz and use the difference between random (NULL) trees to scale.

\textcolor{blue}{The NTS can only -infinity for distances that have the property that the mean distance between random Yule trees is 0. This is not true of either distance metric here. So the real range of values is (mean-max)/mean for both the RF and triples distance.}

%check

\textcolor{blue}{Note that JavaScript is a language, so it a bit confusing to refer to a Java program as a ``Java script."}

%fix

\textcolor{blue}{Equation (6) is not correct. You shouldn't set the summation sign as the left hand side of an equation because the notation has a standard definition. More importantly, the $\#$ of triples is the number of ways of drawing 3 (unordered) leaves from the leaf set. So it is n choose 3 not n choose 4.}

%check

\textcolor{blue}{Equation (7) is true for a three-leaf tree with a polytomy occurring with probability = 1/4 and the other 3 trees being equiprobable. I don't think that is is true for any other weighting of trees for other numbers of taxa. It might be, but the authors must show this.}

%check

\textcolor{blue}{I don't think that equations 8, 9, or 10 are correct for any case other than the 3 taxon case (though I do note that the authors are using n choose 3 here).}

%check

\textcolor{blue}{Equations 13 and 14. It seems easier to just drop the summation sign here, and just define $a_i$ and $b_i$ to the right hand side of these equations.}

%check

\textcolor{blue}{-------------------------}

\textcolor{blue}{6. If you would like your identity to be revealed to the authors, please include your name here (optional).}


\textcolor{blue}{Your name and review will not be published with the manuscript.}


\textcolor{blue}{Reviewer $\#$ 1: No thanks.}

%Fair enough!


\end{letter}
\end{document}
