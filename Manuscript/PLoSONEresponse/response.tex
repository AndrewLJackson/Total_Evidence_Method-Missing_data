\documentclass[11pt]{letter}
\usepackage[a4paper,left=2.5cm, right=2.5cm, top=1cm, bottom=1cm]{geometry}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage[colorlinks = true, urlcolor = blue]{hyperref} %hyperlinks
\usepackage[osf]{mathpazo}
\usepackage{amsmath,amssymb}
\signature{Thomas Guillerme \\ Natalie Cooper}
\address{Zoology building \\ Trinity College Dublin \\ Dublin 2, Ireland \\ \\ guillert@tcd.ie}
\longindentation=0pt
\begin{document}

\begin{letter}{}

RE: PLOS ONE Decision: PONE-D-15-05911 - [EMID:ffa50492e76c2059]

Dear Dr Fontaneto

Please find enclosed our resubmission of our manuscript ``Effects of missing data on topological inference using a Total Evidence approach". We include below details of how we have dealt with the reviewer's comments. Your comments and the reviewers comments are in blue and our response is in black.

% NC: Just send to editor
%We would however, like to draw your attention to a couple of points. Firstly, while we understand the difficulties of obtaining reviewers for papers, we were very disappointed to have the previous decision made based on just one review. As pointed out in your email, this reviewer responded immediately. We suspect they rushed their assessment because they make several comments about our paper that are completely incorrect, and would have been noticed in a thorough reading of the manuscript. We suspect that had a second reviewer been found, the decision might have been different.

%Secondly, the reviewer clearly misunderstood the meaning of the term ``statistics''. Statistics does not mean that p-values need to be used. In this case we could have applied t-tests, and given the reviewer the p-values they request, but this would only tell us that the means of the distributions are significantly different, not that the distributions differ. We chose instead to use the Bhattacharya coefficient, which admittedly is an unfamiliar statistic to many but we feel we made a lot of effort to explain how this metric works in the text (and this method was suggested to us by a professional statistician!). The reviewer however appears to have refused to engage with this and instead has fixated on the lack of p-values.
% NC: Some kind of summing up here

%We are slightly concerned by the reviewer's misconception of the term ``statistics" and suspicions (``I suspect that if they authors take some time to do statistics (calculate some P-values, confidence intervals, or take a Bayesian perspective") since: (1) t-tests and p-values are useful in some cases but have several limitations especially when one compares distributions that are not normal (in this study, we compared the modal value of topological differences, making any test comparing the mean value useless) and can be biased towards small values (i.e. significant ones) when the sample sizes are big; (2) concerning the confidence intervals, we actually did systematically calculate them; ans (3) we are not convinced by a Bayesian approach for comparing distributions.

\textcolor{blue}{
Dear Mr Guillerme, \\
Thank you for submitting your manuscript to PLOS ONE. After careful consideration, we have decided that your manuscript does not meet our criteria for publication and must therefore be rejected. \\
First of all, apologies for the long delays. We immediately received the comments from the first reviewer and in the meanwhile another reviewer agreed to send us comments but failed to do so, even after several reminders. Thus, I now have to reach a decision with only one reviewer.
Unfortunately, the comments from the only reviewer we have are rather negative and the problems that have been highlighted too many. Please, go through all the comments of the reviewer: I think that they all make sense and should be addressed and solved to produce a more convincing and less ambiguous story. \\
If you think that the issues can be solved by new analyses, we will be happy to reconsider a new version of the manuscript as a re-submission. \\
I am sorry that we cannot be more positive on this occasion, but hope that you appreciate the reasons for this decision. \\
Yours sincerely, \\ \\
Diego Fontaneto \\ 
Academic Editor \\
PLOS ONE}

\textcolor{blue}{Reviewers' comments:}

\textcolor{blue}{1. Is the manuscript technically sound, and do the data support the conclusions?}

\textcolor{blue}{Reviewer $\#$ 1: No}

See our detailed response below.

\textcolor{blue}{2. Has the statistical analysis been performed appropriately and rigorously?}

\textcolor{blue}{Reviewer $\#$ 1: No}

See our detailed response below.

\textcolor{blue}{3. Does the manuscript adhere to the PLOS Data Policy?}

\textcolor{blue}{Reviewer $\#$ 1: No}

We apologise for the confusion here. We mentioned where our data was stored in the supporting information but forgot to add this under the "Data Reproducibility and Availability" section in the manuscript. We have now corrected this. 
All the data generated by the simulations are directly available on \href{http://figshare.com/articles/Effect_of_missing_data_on_topological_inference_using_a_total_evidence_approach/1306861}{FigShare}. % add link!!
Note that along with the data we share the full code used for repeating the submitted manuscript, from simulating the data to generating the figures and compiling the manuscript (available on \href{https://github.com/TGuillerme/Total_Evidence_Method-Missing_data}{GitHub}. %add link
All this code is provided with a detailed description of each step that we are happy to develop if needed.

\textcolor{blue}{4. Is the manuscript presented in an intelligible fashion and written in standard English?}

\textcolor{blue}{Reviewer $\#$ 1: Yes}

\textcolor{blue}{5. Review Comments to the Author}

\textcolor{blue}{Reviewer $\#$ 1: This paper tackles an interesting questions. Despite some problems noted below, the experimental design seems adequate.}

%-------------

\textcolor{blue}{Unfortunately the data analysis performed is simply the calculation of a number of summary statistics about the overlap between the estimates returned for different simulation conditions. I suspect that if the authors take some time to do statistics (calculate some P-values, confidence intervals, or take a Bayesian perspective), they'll be able to make a statistical case for most of the points that they are trying to make. But I just don't think that a simulation comparison should be publishable without *some* statistical analysis (beyond the calculation of summaries).}

% Talk to Andrew

%We feel that the reviewer has slightly misunderstood the term ``statistics'' in this case. Firstly, p-values are useful in some cases but have several limitations especially when one compares distributions that are not normal (in this study, we compared the modal value of topological differences, making any test comparing the mean value useless) and can be biased towards small values (i.e. significant ones) when the sample sizes are big; (2) concerning the confidence intervals, we actually did systematically calculate them; ans (3) we are not convinced by a Bayesian approach for comparing distributions.

%-------------

\textcolor{blue}{The bias in the analysis in favor of Bayesian methods makes the recommendation to use Bayesian methods less satisfying.}

% Priors comment??? Move stuff up from below

The reviewer is (I believe) referring to their comment below "". 

Our results did indeed biased us in favour of using a Bayesian approach to fix topology since our results clearly indicate that it is less likely to generate a wrong topology using a Bayesian approach (see Figure 4 and 5 and discussion line 472 to 496 in the first submission manuscript).
% TG: or I'm not sure I understood that one.
%-------------
% add Mk = Mkv

\textcolor{blue}{The use of Mk rather than Mkv makes the study less relevant to real data analyses.}

The Mkv model assumes that all the characters are variable, whereas the Mk model is less constrained - some characters can be invariable and others variable. Thus the Mkv model is actually just a special case of the Mk model.

The reviewer is of course correct in that real data rarely contain invariable morphological characters, because these don't contribute to phylogenetic signal. Our simulated data, on the other hand, will occasionally contain invariable characters merely because of missing data %

However, this is not an issue because we implement opur analyses in RAxML and MrBayes. These programs implement the Mk do not distinguish between both models since the Mkv model is just a particular case of the Mk model and are not distinguished either in the original publication that we cite in the manuscript (Lewis 2001). We've changed the mentions of the M\textit{k} model to M\textit{kv} model throughout the new manuscript.


%Because we sampled the morphological characters rate from a gamma distribution with $\alpha$=0.5, some morphological characters had only a few state changes accross the matrix. When removing the data, there was a probability for these characters to be constant (e.g. if all the taxa in the matrix appart from one had a character state 0 for a given character and only one taxa had a state 1 for the same character, if that taxa had no data available for that character, then the character appeared to be constant in the matrix). 


%Add note that we changed it along the text. RAxML and MrBayes are using default.
%-------------

\textcolor{blue}{Many of the equations are incorrect.}

See our detailed response below.

%-------------

\textcolor{blue}{If there was a mention of the data being deposited, I missed it. I apologize if I did miss it.}

We apologise again for the confusion here. See our comment above on Data Availability and Reproducibility.

%-------------

\textcolor{blue}{-------------------------}

\textcolor{blue}{Some specific concerns:}

% Number the comments


\textcolor{blue}{line 25 and elsewhere: incorrect smart quotes in ``best", ``classical"...}

We fixed the smart quotes in our revision. % change

%-------------

\textcolor{blue}{line 88 ``used it to infer a matrix" $->$ ``used it to simulate a matrix". ``inference" is used in place of simulation elsewhere.}

We changed ``infer" into ``simulate" both at line 88 and in the Figure 1 caption.

%-------------

\textcolor{blue}{line 112: does diversitree just stop simulating when it reaches the correct number of tips, or does it deal with the biases that can result from doing that? (Stadler 2011 is the ref for a discussion of this issues, I believe)}

See our response to the comment ``The procedure for generating a tree with fossils is a valid procedure." below.

%-------------

\textcolor{blue}{line 113: ``rates from a uniform distribution" with what upper and lower bounds?}

Both birth ($\lambda$) and death ($\mu$) parameters are probabilities bounded between 0 and 1. We have added this to the new version of the manuscript:

%-------------

\textcolor{blue}{line 118: with 25 living and 25 fossil taxa. Are the fossils just put at the extinction point for the extinct lineages?}

Yes. We have clarified as follows:

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
[We] select only trees with 25 living and 25 fossil taxa. The fossil taxa were considered as unique tips at the end of extinct lineages. % correct in ms
\end{minipage}

%-------------

\textcolor{blue}{line 110 - line 120. The procedure for generating a tree with fossils is a valid procedure. But it is idiosyncratic, which will make these results harder to relate to other work. Easy of comparability with other work is one of the advantages of using formally characterized models. In this case, I think that using the TreeSim package http://cran.r-project.org/web/packages/TreeSim/TreeSim.pdf would have led to a study with higher impact. This part of the methods section would be reduced to stating the parameter values chosen, and other workers could study similar tree generation simulations. As it stands, it is unlikely that other workers will every generate trees in precisely the way that the authors do. Thus, there will always be a ``however, Guillerme and Cooper generated their trees under a different model..." caveat necessary when discussing this work in the context of other work.}

We do not agree that the procedure is idiosyncratic. \texttt{diversitree} and \texttt{TreeSim} both generate birth-death trees in the same way (although \texttt{diversitree} is slightly quicker) and are well curated and maintained. We chose to use the \texttt{diversitree} package because we are more familiar with it. We could also have used a number of other packages including TESS % cite etc. 
We are also by no means the only people using the diversitree package - the paper associated with it (FitzJohn 2012, Methods in Ecology and Evolution) has been cited three times more (155 cites on Google Scholar) than the publication associated with the \texttt{TreeSim} package (Stadler 2011, Systematic Biology - 55 cites on Google Scholar).
We also disagree that using TreeSim would reduce the amount of explanation required. We believe that carefully outlining our methods will help people repeat our analyses. Thus we would describe any TreeSim analysis in just as much detail.
Finally of course noone can repeat our analyses precisely as we used random parameters to avoid biasing the analyses towards a particular type of tree. We do provide all these trees in the supp mat %link
so future workers can fully repeat our analyses.
Thus we feel that repeating the entire set of simulations (1.5 CPU centuries worth) using TreeSim is not necessary and would not influence our results or their utility to future workers.

%-------------

\textcolor{blue}{line 126 ``random base frequencies" is too vague. Dirichlet(1, 1, 1, 1) perhaps?}

We have clarified as follows:

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
The matrix [...] was generated [...] using the HKY model with random base frequencies (sampled from a uniform probability distribution bounded between 0 and 1 with the total frequency for the four bases equal to 1)[...]
\end{minipage}

%-------------

\textcolor{blue}{Do the simulations apply ascertainment biases as described by Lewis' Mkv (2001) model? It seems like they should... At minimum, the point should be discussed.}

% NEED to fix!

%We are not entirely sure if the reviewers refers to a sampling bias or to the problem link to constant characters described in Lewis (2001) (acquisition bias). If the reviewers are referring to the second (acquisition bias), both phylogenetic inference software we used (RAxML and MrBayes) are correcting for the this bias (-K MK  see Supplementary information 1 for the full list of commands). Also, the effect of the acquisition bias is to inflate branch length which is an aspect of the phylogeny we didn't explored in this study (focusing on topology). See response below to the comment ``\textit{The use of Mk rather than Mkv makes the study less relevant to real data analyses.}".

%-------------

\textcolor{blue}{line 171 - 177: the authors need to explain the order of operations for the $M_F$ vs $M_C$ masking. It makes a difference. If you mask out $M_F$ percentage of cells, and then mask $M_C$ percentage of columns, it is possible (indeed very probable) that the percentage of missing data in fossil characters that remain will not be $M_F$ after some of the morphological columns are removed. If you mask by $M_C$ first, and then $M_F$, the resulting matrices will always have $M_F$ percentage missing data (modulo rounding error) in the simulated realizations.}

We clarified this point ($M_C$ comes second) in the new version of the manuscript (see below). Also, we clarified the potential confusion between the amount of data removed in one parameter ($M_F$ = 10\% for example) and the amount of missing data in the morphological matrix (5\%).

Lines @@@112 to @@@114 in the new manuscript: 

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
In practice, each parameter represents a different way of removing data from the matrix: $M_L$ removes rows from the living taxa's data; $M_F$ removes cells from the fossil taxa's data; and $M_C$ removes columns across both living and fossil taxa's data. Note that $M_L$ and $M_F$ differ not only because of the region of the matrix affected: for $M_L$ all the morphological data of a percentage of living taxa are removed, whereas for $M_F$ a percentage of the data are removed at random from across the whole of the morphological matrix for fossil taxa. We first applied the parameters $M_L$ and $M_F$ on the matrix and then applied the $M_C$ parameter. Therefore, when 10\% data was missing for both $M_L$ and $M_F$, 10\% data was missing in the morphological part of the matrix. However, when applying the $M_C$ parameter with the same rate (10\%) the resulting matrix potentially had more than 10\% data missing.
\end{minipage}

%-------------

\textcolor{blue}{Header for 3. should be ``building phylogenetic estimates" or ``estimating phylogenies" because the previous section described how the phylogenies and character data were ``built."}

We changed the Header 3 to ``Estimating phylogenies".

%-------------

\textcolor{blue}{RAxML searching: it would be nice to see some searches started from the true tree. This is clearly not an option for real data sets, but it is helpful in simulation studies because it lets the reader determine if the results could be an artifact of insufficient tree searching.}

Our simulations were designed to test the effects of missing data in as realistic a manner as possible given our constraints. Thus, we do not feel that this additional analysis would add much to the paper, especially since it is already rather long and complex. 

%-------------

\textcolor{blue}{Filtering the data sets for strong bootstrap support under the full data analysis surely introduces some bias in favor of the no-missing data analyses.}

We implemented this step of keeping trees with a minimum total median bootstrap to make the topological comparisons more robust. If the no-missing data tree has low node support, it is likely that the changes in topology for the missing data trees are not linked to our focal question (the effect of removing characters, living taxa or fossils) but just to the fact that low supported nodes can be just random. We've added the following justification in the new manuscript:

% NC: expand on this a bit

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
We repeated this selection until we obtained 50 sets of simulations (i.e. 50 ``complete" and 50 x 125 ``missing-data" matrices) with a relatively strong phylogenetic signal (median bootstrap $>$ 50). This step was implemented to make sure that the differences we observed in topologies (see below) where due to the amount of missing data for each parameters ($M_L$, $M_F$ and $M_C$) and not simply to low branch support that is likely to lead to different topologies.
\end{minipage}

%-------------

\textcolor{blue}{MrBayes: using strongly informative priors for the true parameters does more than speed up the searching, it represents an ``unfair" advantage (an option that would not be available in real data analysis in which one does not know the true values) for the Bayesian method. This makes the studies report of superior behavior of Bayesian methods less persuasive.}

We would like to emphasize that in this study we focused on the effect of missing data in the morphological part of the matrix on topology only. The choice of the following priors (``exponential prior on the shape of the gamma distribution of $\alpha$ = 0.5 for both partitions" (line 228) and the ``transition/transversion ratio prior of two sampled from a strong beta 229 distribution ($\beta$(80,40))" (line 229)) affected mainly the molecular part of the matrix that remains constant (gamma distribution and transition/transversion ratio) and were a minor part of the MCMC sampler (2.17\% of move probability% check what you call it in paper
 for the three priors). 

% Most of the effects will be branch length and we don't look at that

 Therefore we are confident that the topology is minimally affected by the priors, allowing us to explore the effect of missing morphological data on topology as well as reducing our computational time to a realistic 1.5 CPU centuries.

% Add something to text?

%-------------

\textcolor{blue}{line 254: RF measures the difference between the number of clades and the twice number of shared clades across two trees. The statement that it ``measures the number of shared clades across two trees" should be revised.}

We changed the following sentence: % correct

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
The Robinson-Foulds distance, or ``path difference", measures the difference between the number of clades and the twice number of shared clades across two trees.
\end{minipage}

%-------------

\textcolor{blue}{line 258: RF is 0 (not 1) when the trees are identical. It's maximum (for 2 rooted binary trees) is 2(n-2) not n-2.}

% Say thanks for this!
We changed the following sentence:

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
This metric is bounded between zero, when the two trees are identical, and $2(n-2)$ (for two trees with $n$ taxa) when there is no shared clade in the two trees.
\end{minipage}

%%%%%%%%%%%%%%%%%
%CHECK in Soltis!
%%%%%%%%%%%%%%%%%

%-------------

\textcolor{blue}{The ``scaling" to produce the Normalized RF ``distance" is confusing. It is also inverting the sign of the distance, so it has become a measure of similarity.}

We agree that this is confusing and thank the reviewer for pointing this inconsistency out. 
We clarified the scaling method as follows: % change from distance to metric???

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
We normalised this metric following Bogdanowicz \textit{et al.} (2012)'s Normalised Tree Similarity (NTS) method. This methods scales %not sure if scale here?
any tree comparison metric using the mean distance between 1000 random trees (see Supporting Information S2: Tree Comparisons for the calculation details). This method is a generalisation of the topological accuracy method (Price \textit{et al.} 2010) allowing to compare topological differences between any tree with any tree comparison metric. In practice when the Normalised Robinson-Foulds distance between two trees is equal to one, the trees are identical; if the distance is equal to zero, the trees are no more different than expected by chance; finally if the distance is less than zero, the trees are more different than expected by chance.
\end{minipage}


% Note that NRF distance is actually a similarity ...

%-------------

\textcolor{blue}{line 275: why isn't the upper bound of the triples distance n choose 3 (instead of n choose 4). I think you got the formula from an unrooted quartet distance.}

We changed the following sentence: % fix

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
It is bounded between zero when the two trees are identical and $\binom{n}{3}$ (for two trees with $n$ taxa) when there is no shared taxa/clade position in the two trees.
\end{minipage}

%%%%%%%%%%%%%%%%%
%CHEK in Soltis!
%%%%%%%%%%%%%%%%%

%-------------

\textcolor{blue}{Using the BC stat may be similar in spirit to using a t-test, but it is not equivalent.}

We clarified this point in the text as well as in the figures 2 and 3 captions (``equivalent" $->$ ``similar"):

Lines 308 to 309 in the previously submitted manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
Note that this is equivalent to performing a two-sided t-test.
\end{minipage}

Lines @@@112 to @@@114 in the new manuscript:

\hfill\begin{minipage}{\dimexpr\textwidth-1cm}
Note that this is similar to performing a two-sided t-test for comparing two distribution.
\end{minipage}

%-------------

\textcolor{blue}{Figure 3: B is confusing. If both curves are probability distributions, then they both have to integrate to 1. So B(y) can't cover just a subset of the area covered by B(x).}

% frequency! correct.

%I'm not sure how to fix that comment. The figure caption says (first sentence!) : "A and B are distributions of tree similarity metrics (Normalised Robinson-Foulds or Normalised Triplets distances) for any combination of missing data parameters (e.g. ML = 10%,MF = 50%, MC = 75%)." Should I make it super clear by writing : "A and B are distributions of tree similarity metrics (not probability distributions, or roller coasters plans)" ?

%-------------

\textcolor{blue}{``Combined effect of missing data parameters" section ANOVA or multiple regression are the appropriate analyses to tease apart multiple interacting factors. Here the authors opt to describe results without statistical tests, which is disappointing.}

This comment links back to the reviewer's slight misconception of the term ``statistics". ANOVA or multiple regression analysis might the appropriate analyses in some cases but we believe it isn't here. In our analysis, we made the methodological choice to compare tree similarity distributions that are: not continuous distributions; bounded at 1; not always normal (both the distributions and the residuals) and sometimes multi-modal. Therefore, we choose not to use classical ``statistics" methods such as ANOVA or multiple regression because these methods could simply not be applied to our data set.
%Not comparing means, non normal distributions. And non-parametric version (e.g. Kruskal Wallis) not approriate either.

% Talk to Andrew

%-------------

\textcolor{blue}{line 398: ``mMthods" $->$ ``Methods"}

We fixed this typo.

\textcolor{blue}{line 420: contra the statement here, a consensus collapsing to a polytomy will affect the RF distance (could go up or down, but it will change).}

%To 

This does not decrease the 420
Normalised Robinson-Foulds distance, because clades are conserved, but decreases the 421
Normalised Triplets distance because the fossils act as wildcard taxa. 422


%Change to "affect less" or something like that.

%-------------

%So for the part about the tree comparisons (RF and Triplets, I think we can just remove the whole thing since it's not especially useful...)

We recognise that this section in our supp mat may be confusing and is actually unnecessary for the understanding the paper. Therefore we have removed this section. % fix!!!

\textcolor{blue}{Supplement 2:}
\textcolor{blue}{more confusion about the min RF here. Also note that if you are counting the entire leaf set as a clade (e.g the star tree having N=1), then the number of clades in rooted binary tree is n-1 (not n-2). Equation 3 has an extra ``-2" As stated it implies that the max RF distance for n=3 is 0, when the correct answer is 2.}

%check

%-------------

\textcolor{blue}{The definition of the scaled RF implies that it is never positive (sinc the numerator cannot be positive and the denominator is positive).}

%not in this paper

%-------------

\textcolor{blue}{The decision to use Yule trees as the base line for the mean distance is not explained, and seems odd given that the true tree are not Yule trees. I'm not sure that it makes much difference, but it is odd.}

We cited the reference (Bogdanowicz 2012) of the method.
%explain in a bit more detail

%-------------

\textcolor{blue}{The NTS can only -infinity for distances that have the property that the mean distance between random Yule trees is 0. This is not true of either distance metric here. So the real range of values is (mean-max)/mean for both the RF and triples distance.}

As clarified in the new manuscript (lines @@@), the NTS is a generalisation of the topological accuracy method (Price \textit{et al.} 2010 PLoS ONE) and is therefore not specialised for the RF or the Triples distance.

%-------------

\textcolor{blue}{Note that JavaScript is a language, so it a bit confusing to refer to a Java program as a ``Java script."}

We fixed this typo.

%-------------

\textcolor{blue}{Equation (6) is not correct. You shouldn't set the summation sign as the left hand side of an equation because the notation has a standard definition. More importantly, the $\#$ of triples is the number of ways of drawing 3 (unordered) leaves from the leaf set. So it is n choose 3 not n choose 4.}

%check

%-------------

\textcolor{blue}{Equation (7) is true for a three-leaf tree with a polytomy occurring with probability = 1/4 and the other 3 trees being equiprobable. I don't think that is is true for any other weighting of trees for other numbers of taxa. It might be, but the authors must show this.}

%check

%-------------

\textcolor{blue}{I don't think that equations 8, 9, or 10 are correct for any case other than the 3 taxon case (though I do note that the authors are using n choose 3 here).}

%check

%-------------

\textcolor{blue}{Equations 13 and 14. It seems easier to just drop the summation sign here, and just define $a_i$ and $b_i$ to the right hand side of these equations.}

We fixed this by removing the summation signs.


\end{letter}
\end{document}
